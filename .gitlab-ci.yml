# Author: Daniel J.Mazure
# Date: 05.12.2021
# Description: GitLab CI configuration script.

# Tests over the FPGA set to manual temporarily until one specific machine is devoted
# to that task.
#
# The CI/CD flow generates a bitstream both for the targeted EA.
# The Pipeline can be triggered if there is an update (rule "changes") in the
# ea_url.txt file/folder
# TODO: [Documentation] References are mandatory to exist in the EA included yml

# Include the supported EA configuration files. This could be done in other
# included file for clarity

include:
  - local: cicd/ea_conf.yml
  - local: support/ox/setup.yml

# The workflow includes all the necessary rules to run all the jobs in this .gitlab-ci.yml.
# The pipeline ca be trigger for:
# pipeline: Multi-project pipelines
# merge_request_event: to production branch
# Using web
# Tag
# The specifics for each environment

workflow:
  rules:
    - if: $CI_PIPELINE_SOURCE == "pipeline"
    - if: $CI_PIPELINE_SOURCE == "parent_pipeline"
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"
    - if: $CI_PIPELINE_SOURCE == "web"
    - if: $CI_COMMIT_BRANCH && $CI_OPEN_MERGE_REQUESTS
      when: never
    - if: $CI_COMMIT_TAG != null
    - if: $CI_COMMIT_BRANCH == "main" && $CI_PIPELINE_SOURCE == "push"
      when: never # Pushing to main doesn't create pipelines unless there is a tag
    - !reference [.test_rules, rules]
    - !reference [.production_rules, rules]
    - !reference [.quick_test_rules, rules]

variables: !reference [.setup, variables]

stages:
  - synthesis
  - implementation
  - bitstream
  - test
  - deploy

.clone_ea: &clone_ea
  # This is a Gitlab CI/CD requirement. Use a token-ed URL instead of the regular one.
  # The load_module script loads the txt file in the support folder.
  # The hidden job substitute the SHA in case this is a triggered pipeline
  # The extract_url script inserts the token into the repo URL.
  - echo "Inserting the Gitlab token in the EA's URL"
  - sh/load_module.sh $EMULATED_ACCELERATOR
  - echo "$COMMIT_SHA"; echo "Actual URL:"; cat ea_url.txt
  - echo "CommitREF is $COMMIT_REF"; echo "The commit SHA is $COMMIT_SHA"
  - !reference [.update_sha, script]
  - echo "After update_sha:"; cat ea_url.txt
  - sh/extract_url.sh ea_url.txt $CI_BUILD_TOKEN
  - echo "After update_sha:"; cat ea_url.txt

# EMULATED_ACCELERATOR might be an export variable instead of a GitLab one.
# Then, before script can setup this bash variable depending on the value
# of the EA matrix/parallel value. This way we can clone other EAs

synthesis:
  stage: synthesis
  rules:
    - !reference [.production_rules, rules]
    - !reference [.quick_test_rules, rules]
  interruptible: true
  retry: 1
  tags:
    - synthesis
  timeout: 72h
  variables:
    GIT_STRATEGY: clone
    GIT_SUBMODULE_STRATEGY: "recursive"
    GIT_CLONE_PATH: $CI_BUILDS_DIR/$CI_CONCURRENT_ID/${EA}_${FPGA_BOARD}
  before_script:
    - !reference [.git_clean, before_script]
    - *clone_ea
    - git config --global url."https://gitlab-ci-token:${CI_JOB_TOKEN}@gitlab.bsc.es/".insteadOf "https://gitlab.bsc.es/"
    - echo $USER
  script:
    - echo "[DEBUG] synthesis"
    - make initialize
    - make $FPGA_BOARD
    # Synthesis production will use Pronoc routers
    - make project
    - make synthesis
    - !reference [.check_synth, script]
  after_script:
    - mkdir -p tmp/project
    - cp ea_url.txt tmp/EA_info.txt
    - cp shell_build.log tmp/project/
    - cp -r src/system_top.sv tmp/project/
    - cp -r tcl/shell_env.tcl tmp/project/
    - cp gen_system.tcl tmp/project/
    - mv dcp/synthesis.dcp dcp/synthesis_${EA}_${FPGA_BOARD}.dcp
    - echo -e "Artifacts:"; ls tmp; ls dcp
  allow_failure: false # If any sinthesys fails, all fails
  artifacts:
    when: always
    expire_in: 3 day
    paths:
      - tmp
      - dcp/synthesis_${EA}_${FPGA_BOARD}.dcp

implementation:
  stage: implementation
  rules:
    - !reference [.production_rules, rules]
    - !reference [.quick_test_rules, rules]
  needs: [synthesis]
  tags:
    - synthesis
  timeout: 72h
  variables:
    GIT_STRATEGY: fetch
    GIT_CLONE_PATH: $CI_BUILDS_DIR/$CI_CONCURRENT_ID/${EA}_${FPGA_BOARD}
  before_script:
    - mv dcp/synthesis_${EA}_${FPGA_BOARD}.dcp dcp/synthesis.dcp #?
  script:
    - make ci_implementation DCP_ON=false
    - !reference [.check_impl, script]
  after_script:
    - mv dcp/implementation.dcp dcp/implementation_${EA}_${FPGA_BOARD}.dcp
    - echo -e "Artifacts:"; ls dcp; ls reports
    - mv reports reports_${EA}_${FPGA_BOARD}
  artifacts:
    when: always
    expire_in: 2 day
    paths:
      - dcp/implementation_${EA}_${FPGA_BOARD}.dcp
      - reports_${EA}_${FPGA_BOARD}

bitstream:
  variables:
    DESIRED_FORMAT: "%Y%m%d"
    GIT_STRATEGY: fetch
    GIT_CLONE_PATH: $CI_BUILDS_DIR/$CI_CONCURRENT_ID/${EA}_${FPGA_BOARD}
  stage: bitstream
  tags:
    - synthesis
  timeout: 72h
  rules:
    - !reference [.production_rules, rules]
    - !reference [.quick_test_rules, rules]
  needs: [implementation]
  before_script:
    - mv dcp/implementation_${EA}_${FPGA_BOARD}.dcp dcp/implementation.dcp
  script:
    - make ci_bitstream
  after_script:
    # The UTC datetime when the pipeline was created
    - date_format="$(date -d "$CI_COMMIT_TIMESTAMP" +"$DESIRED_FORMAT")"
    - make clean_implementation
    - mv bitstream/system.bit bitstream/${date_format}_${EA}_${FPGA_BOARD}.bit
    - echo -e "Artifacts:"; ls bitstream
    # Store the Job ID to identify later the path to the bitstream artifact
    - echo BS_CI_JOB_ID_${EA}_u55c=$CI_JOB_ID >> gen_bitstream.env
  artifacts:
    when: always
    expire_in: 5 days
    paths:
      - bitstream
    reports:
      dotenv: gen_bitstream.env

reports:
  stage: bitstream
  variables:
    GIT_STRATEGY: fetch
    GIT_CLONE_PATH: $CI_BUILDS_DIR/$CI_CONCURRENT_ID/${EA}_${FPGA_BOARD}
  rules:
    - !reference [.production_rules, rules]
    - !reference [.quick_test_rules, rules]
  tags:
    - synthesis
  timeout: 72h
  needs: [implementation]
  before_script:
    - mv dcp/implementation_${EA}_${FPGA_BOARD}.dcp dcp/implementation.dcp
  script:
    - echo "Generate implementation reports..."
    - make ci_report_route
    - make validate
  after_script:
    #- !reference [.reports_data, after_script]
    - ls reports
    - mkdir -p tmp/reports
    - mv reports reports_${EA}_${FPGA_BOARD}
  artifacts:
    when: always
    expire_in: 2 days
    paths:
      - reports_${EA}_${FPGA_BOARD}

##################
### Tests jobs ###
##################

#1. Boot Buildroot/linux
# The entire fpga-test is EA dependant, it should probably be a job from an included file
fpga-test-linux:
  variables:
    DESIRED_FORMAT: "%Y%m%d"
    GIT_STRATEGY: fetch
    GIT_CLONE_PATH: $CI_BUILDS_DIR/$CI_CONCURRENT_ID/${EA}_${FPGA_BOARD}
  stage: test
  retry: 2
  timeout: 6h
  rules:
    - !reference [.production_rules, rules]
    - !reference [.quick_test_rules, rules]
  needs: [bitstream]
  # Overwrite tags to select the right board
  tags:
    - $FPGA_BOARD
  before_script:
    - !reference [.fpga_test, before_script]
    # The UTC datetime when the pipeline was created
    - date_format="$(date -d "$CI_COMMIT_TIMESTAMP" +"$DESIRED_FORMAT")"
    - export BITSTREAM=bitstream/${date_format}_${EA}_${FPGA_BOARD}.bit
  script:
    # The EA script should provide the right script and the right binary
    - ./fpga-tools/fpga/load-bitstream-onic.sh qdma $BITSTREAM
    - !reference [.fpga_test, script]
    - ./fpga-tools/fpga/fpga_test.sh $FPGA_LOG_TEST_BUILDROOT "sargantana login:"
  after_script:
    - mkdir -p tmp/logs
    - cp $FPGA_LOG_TEST_BUILDROOT tmp/logs/$FPGA_LOG_TEST_BUILDROOT
  allow_failure: false
  artifacts:
    when: always
    expire_in: 2 days
    paths:
      - tmp
